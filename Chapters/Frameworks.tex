\section{Frameworks}

General introduction to NN training and modern frameworks, tell about
TensorFlow, PyTorch, Caffe. How they support different devices, and how
this becomes increasingly important with the Moore's Law. Mention that this
is an important area of research, as it will yield big performance gains.

Neural networks are becoming an increasingly important instrument in todays research and
real-world applications, applied across wide spectrum of areas like Vision \cite{ImageNet},
Speech recognition \cite{Baidu}, Machine translation \cite{GoogleNMT} and many others.
This is due to the fact that neural networks have several desirable properties: they are very
good at approximating very complex functions, something that is required for high-dimensional
perception tasks. Also, their structure in very modular by nature and they can be combined in
more complicated patterns, just like a regular functions in programming language. For example,
one module will contribute the memory capabilities to remember words in machine translation
task, and other module will provide attention mechanism to pick relevant words in translated
sentence.
On the downside, training neural networks is notoriously difficult and expensive process,
that involves huge amount of computation resources over time \cite{LongTraining}.
This problem is being constantly attacked from three different angles:
\begin{enumerate}
    \item Improving the data efficiency of training algorithms - there is a permanent effort on
        improving optimization and learning techniques \cite{Adam},\cite{ImageNetInHour}, \cite{BatchNorm}.

    \item Improving the hardware performance - the first successful example of using specific
        hardware to improve training was the use of GPUs to train on Vision datasets \cite{NgCudnn}, \cite{AlexNet}.
        At that point, ability to efficiently train networks on GPU was a lucky coincidence, and
        required a huge effort to adapt the training code to specific hardware specific language that
        was mainly oriented for graphics and gaming programming. Now, the hardware is built with
        the specific goal of training neural networks in mind, allowing to have much bigger performance
        gains comparing to the general purpose CPUs. There are several big players in this area,
        notably NVidia \cite{NVidiaGPU}, Intel \cite{Nervana} and Google \cite{TPU}

    \item Improving the tooling around training - building clever software frameworks, that will 
        both allow the use the best practices for training, and utilize the unrelying hardware
        in the most efficient manner. Before the development of modern training frameworks, the process
        of describing your machine learning model involved writing a lot of code for linear algebra
        manipulations in a very low-level \cite{FORTRAN}, \cite{NumPy}, and any change to the model
        or the training procedure could lead to huge changes in code.
        Nowdays it's possible to describe efficient model in 10 lines of Python code and expect
        a performance as if it was written in high-performant language like C++.
        Also, some of the frameworks make the process of scaling the model training to multiple machines
        incredibly simple, freeing the user from thinking about explicit network communication and
        fault tolerance \cite{TensorFlow}.
        Different frameworks now address the questions of performance, scalability and usability.
        - The frameworks are usually implemented with low-level language like C, C++ under the hood, and expose
        a convenient interface in high-level language (Python, Lua, links to TF, Torch, PyTorch),
        that improves usability but sometimes greatly limits performance (tell about GIL lock in Python).
\end{enumerate}

An important observation here is that algorithms, hardware and frameworks are tightly connected,
and usually co-evolve. That's why to ensure that the sum is bigger then the individual parts,
it's important to have a constant feedback loop between hardware vendors, research community
and machine learning practitioners. Many hardware companies now have research groups
that publish papers in machine learning space \cite{GA3C}, \cite{IntelVizDoom}, and in opposite,
several big IT companies have a dedicated hardware department \cite{TPU}, \cite{AppleCore}.

- Add information about CUDNN and XLA compiler.

Another important avenue of research that is particularly compelling for the big players on the machine
learning arena that are ready to trade resources for final quality of the models and training time
are scalable architectures, that can utilize hundreds of computing nodes
in parallel. This can both decrease the training time from weeks to hours, and also allow
serving millions of customers in real-time. The examples of this direction include systems
that use MapReduce \cite{MapReduce} framework to train large linear models \cite{Sibyl},
Spark iterative computation model \cite{MLLib}, more modern and flexible Parameter Server architecture
for asynchronous distributed stochastic gradient descent \cite{Hogwild}, systems for model- and
data-parallel training of neural networks \cite{DistBelief}, and systems distributed
Reinforcement Learning training \cite{GORILA}.

